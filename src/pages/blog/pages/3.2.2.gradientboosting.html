<h1>GRADIENT BOOSTING</h1>

<p>Gradient Boosting is type of boosting model. It is a popular model for classification and regression problems. It is a non-parametric model that builds a tree-like structure to make predictions.</p>

<h2>Types of Gradient Boosting</h2>
<p>There are 3 types of Gradient Boosting:</p>
<ul>
  <li>XGBoost</li>
  <li>LightGBM</li>
  <li>CatBoost</li>
</ul>
<h2>Learning process</h2>
<p>Boosting Model learning between node, improve the model by loss function. This example work on Logistic Loss</p> 
<p>The loss function is given by:</p>
<p>
    $$L(y, \hat{y}) = -\frac{1}{n} \sum_{i=1}^{n} \left( y_i \log(\hat{y}_i) + (1 - y_i) \log(1 - \hat{y}_i) \right)$$
</p>
<p>where $n$ is the number of samples, $y_i$ is the actual value, and $\hat{y}_i$ is the predicted value.</p>
<p>Log Loss is used in binary classification problems.</p>
<p>The loss function is used to improve the model by minimizing the loss function.</p>
<p> </p>

